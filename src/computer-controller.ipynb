{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n"
     ]
    }
   ],
   "source": [
    "%env PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel_devcloud_support'))\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h5>Demo</h5>\n",
       "        <video alt=\"\" controls autoplay muted height=\"480\"><source src=\"/data/demo.mp4\" type=\"video/mp4\" /></video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import videoHtml\n",
    "videoHtml.videoHTML('Demo', ['/data/demo.mp4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python3 /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name face-detection-adas-binary-0001 --output_dir /data/models\n",
    "!python3 /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name head-pose-estimation-adas-0001 --output_dir /data/models\n",
    "!python3 /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name landmarks-regression-retail-0009 --output_dir /data/models\n",
    "!python3 /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name gaze-estimation-adas-0002 --output_dir /data/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting queue_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile queue_job.sh\n",
    "#!/bin/bash\n",
    "\n",
    "exec 1>/output/stdout.log 2>/output/stderr.log\n",
    "\n",
    "mkdir -p $1\n",
    "OUTPUT_FILE=$1\n",
    "DEVICE=$2\n",
    "PRECISION=$3\n",
    "INPUT_FILE=$4\n",
    "THRESHOLD=$5\n",
    "\n",
    "if [ \"$PRECISION\" = \"FP32\" ]; then\n",
    "    FACEMODELPATH=/data/models/intel/face-detection-adas-binary-0001/FP32-INT1/face-detection-adas-binary-0001.xml\n",
    "    POSEMODELPATH=/data/models/intel/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001.xml\n",
    "    LANDMARKSMODELPATH=/data/models/intel/landmarks-regression-retail-0009/FP32/landmarks-regression-retail-0009.xml    \n",
    "    GAZEMODELPATH=/data/models/intel/gaze-estimation-adas-0002/FP32/gaze-estimation-adas-0002.xml        \n",
    "else\n",
    "    FACEMODELPATH=/data/models/intel/face-detection-adas-binary-0001/FP32-INT1/face-detection-adas-binary-0001.xml\n",
    "    POSEMODELPATH=/data/models/intel/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml\n",
    "    LANDMARKSMODELPATH=/data/models/intel/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009.xml    \n",
    "    GAZEMODELPATH=/data/models/intel/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002.xml        \n",
    "fi\n",
    "\n",
    "if echo \"$DEVICE\" | grep -q \"FPGA\"; then # if device passed in is FPGA, load bitstream to program FPGA\n",
    "    #Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    source /opt/intel/init_openvino.sh\n",
    "    aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/2019R4_PL1_FP16_MobileNet_Clamp.aocx\n",
    "fi\n",
    "\n",
    "ls /data/*\n",
    "\n",
    "python3 main.py -fm ${FACEMODELPATH} \\\n",
    "                -pm ${POSEMODELPATH} \\\n",
    "                -lm ${LANDMARKSMODELPATH} \\\n",
    "                -gm ${GAZEMODELPATH} \\\n",
    "                -i ${INPUT_FILE} \\\n",
    "                -o ${OUTPUT_FILE} \\\n",
    "                -d ${DEVICE} \\\n",
    "                -c ${THRESHOLD}\n",
    "\n",
    "cd /output\n",
    "\n",
    "tar zcvf output.tgz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"CPU\"\n",
    "output_path = \"/output/results/controller\"\n",
    "precision = \"FP32\"\n",
    "thres=0.5\n",
    "input_file = \"demo.mp4\"\n",
    "params = ' {} {} {} {} {}'.format(output_path, device, precision, input_file, thres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = !qsub queue_job.sh -l nodes=1:tank-870:i5-6500te -d . -F \"{params}\" -N \"cpu\" -wd ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BATtMXtL9lAg616irAoYSgUPIW8dhQPq'"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "import liveQStat\n",
    "liveQStat.liveQStat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getResults() is blocking until results of the job (id:BATtMXtL9lAg616irAoYSgUPIW8dhQPq) are ready.\n",
      "Please wait.......Success!\n",
      "output.tgz was downloaded in the same folder as this notebook.\n"
     ]
    }
   ],
   "source": [
    "import get_results\n",
    "get_results.getResults(job_id[0], filename='output.tgz', blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"main.py\", line 266, in <module>\r\n",
      "    main()\r\n",
      "  File \"main.py\", line 77, in main\r\n",
      "    assert os.path.isfile(args.input), \"Specified input file doesn't exist\"\r\n",
      "AssertionError: Specified input file doesn't exist\r\n"
     ]
    }
   ],
   "source": [
    "!tar zxf output.tgz\n",
    "!cat stderr.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/fetch_model.ipynb\r\n",
      "/data/videofile.mp4\r\n",
      "\r\n",
      "/data/legacy_ignore:\r\n",
      "data\r\n",
      "\r\n",
      "/data/models:\r\n",
      "intel\r\n",
      "\r\n",
      "/data/queue_param:\r\n",
      "manufacturing.npy\r\n",
      "retail.npy\r\n",
      "transportation.npy\r\n",
      "\r\n",
      "/data/resources:\r\n",
      "car.png\r\n",
      "manufacturing.mp4\r\n",
      "retail.mp4\r\n",
      "transportation.mp4\r\n",
      "Arg input demo.mp4\r\n",
      "results/\r\n",
      "results/controller/\r\n",
      "stderr.log\r\n"
     ]
    }
   ],
   "source": [
    "!cat stdout.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"VIDEO\"] = \"bin/demo.mp4\"\n",
    "!ln -sf ./bin/demo.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
